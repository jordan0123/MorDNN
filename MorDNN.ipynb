{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Imports</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob, os\n",
    "import random\n",
    "import sklearn\n",
    "import tensorflow as tf  \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, LSTM, GRU, LeakyReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Config Tensorflow to use GPU</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce RTX 2080, pci bus id: 0000:08:00.0, compute capability: 7.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = tf.compat.v1.ConfigProto()  \n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU  \n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)  \n",
    "                                    # (nothing gets printed in Jupyter, only if you run it standalone)\n",
    "sess = tf.compat.v1.Session(config=config)  \n",
    "tf.compat.v1.keras.backend.set_session(sess)  # set this TensorFlow session as the default session for Keras  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load full sequences</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sequences = []\n",
    "\n",
    "for file in glob.glob(\"C:\\\\Users\\\\Jordan\\\\Desktop\\\\MorDNN\\\\*.txt\"):\n",
    "    data_file = open(file)\n",
    "    full_sequences.append( data_file.readlines() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create sub-sequences for training</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103228, 200, 79)\n",
      "(103228, 200, 21)\n",
      "(103228, 200, 2)\n"
     ]
    }
   ],
   "source": [
    "seq_len = 200 # length of sequences to train on\n",
    "\n",
    "data_x = []\n",
    "data_y1 = []\n",
    "data_y2 = []\n",
    "\n",
    "for sequence in full_sequences:\n",
    "    num_samples = len(sequence) // 3\n",
    "    \n",
    "    sequence_x = []\n",
    "    sequence_y1 = []\n",
    "    sequence_y2 = []\n",
    "    \n",
    "    # format data into input list and output lists\n",
    "    for i in range (0, (num_samples - 1) * 3, 3):\n",
    "        # align current state with outputs for t+1 \n",
    "        sequence_x.append(np.fromstring(sequence[i], dtype='float', sep=' ')[0:79])\n",
    "        sequence_y1.append(np.fromstring(sequence[i + 1 + 3], dtype='float', sep=' '))\n",
    "        sequence_y2.append(np.fromstring(sequence[i + 2 + 3], dtype='float', sep=' '))\n",
    "        \n",
    "    data_x.append(sequence_x)\n",
    "    data_y1.append(sequence_y1)\n",
    "    data_y2.append(sequence_y2)\n",
    "    \n",
    "x_train = []\n",
    "y1_train = []\n",
    "y2_train = []\n",
    "    \n",
    "for i in range(0, len(data_x)):\n",
    "    num_samples = len(data_x[i])\n",
    "    \n",
    "    j = 0\n",
    "    while j < num_samples - seq_len:\n",
    "        subseq_x = []\n",
    "        subseq_y1 = []\n",
    "        subseq_y2 = []\n",
    "        \n",
    "        for k in range(j, j + seq_len):\n",
    "            subseq_x.append(data_x[i][k])\n",
    "            subseq_y1.append(data_y1[i][k])\n",
    "            subseq_y2.append(data_y2[i][k])\n",
    "        \n",
    "        x_train.append(subseq_x)\n",
    "        y1_train.append(subseq_y1)\n",
    "        y2_train.append(subseq_y2)\n",
    "        \n",
    "        j = j + 1\n",
    "        \n",
    "del full_sequences\n",
    "del data_x\n",
    "del data_y1\n",
    "del data_y2\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y1_train = np.array(y1_train)\n",
    "y2_train = np.array(y2_train)\n",
    "\n",
    "num_features = x_train[0][0].size\n",
    "output_size_y1 = y1_train[0][0].size\n",
    "output_size_y2 = y2_train[0][0].size\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y1_train.shape)\n",
    "print(y2_train.shape)\n",
    "\n",
    "'''\n",
    "seq_len = 200 # length of subsequences to train on\n",
    "\n",
    "train_x = []\n",
    "train_y1 = []\n",
    "train_y2 = []\n",
    "\n",
    "# for every full sequence (1 data file)\n",
    "for i in range(0, len(full_sequences)):\n",
    "    num_samples = len(full_sequences[i]) // 3\n",
    "    \n",
    "    # for each sample in the full sequence, make a subsequence from a window from j to j + seq_len\n",
    "    # num_samples - 1 b/c we are training on the output at the next timestep\n",
    "    for j in range(0, (num_samples - 1 - seq_len) * 3, 3):\n",
    "        subsequence_x = []\n",
    "        subsequence_y1 = []\n",
    "        subsequence_y2 = []\n",
    "        \n",
    "        # for each sample in the window\n",
    "        for k in range(j, j + seq_len * 3, 3):\n",
    "            # game state (input)\n",
    "            subsequence_x.append( np.fromstring(full_sequences[i][k], dtype='float', sep=' ')[0:79] )\n",
    "\n",
    "            # outputs (add 3 b/c each sample is 3 lines and we are training on outputs for the timestep of t + 1)\n",
    "            subsequence_y1.append( np.fromstring(full_sequences[i][k + 1 + 3], dtype='float', sep=' '))\n",
    "            subsequence_y2.append( np.fromstring(full_sequences[i][k + 2 + 3], dtype='float', sep=' '))\n",
    "            \n",
    "        train_x.append(subsequence_x)\n",
    "        train_y1.append(subsequence_y1)\n",
    "        train_y2.append(subsequence_y2)\n",
    "        \n",
    "train_x = np.array(train_x)\n",
    "train_y1 = np.array(train_y1)\n",
    "train_y2 = np.array(train_y2)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y1.shape)\n",
    "print(train_y2.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 200, 79)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 200, 600)     1632000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 200, 600)     0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 200, 500)     2202000     dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 200, 500)     0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 200, 200)     100200      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 200, 200)     0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 200, 200)     0           leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_out1 (Dense)              (None, 200, 21)      4221        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_out2 (Dense)              (None, 200, 2)       402         dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,938,823\n",
      "Trainable params: 3,938,823\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = False\n",
    "checkpoint_path = \"checkpoint_1\\\\cp.ckpt\"\n",
    "\n",
    "# creates the neural network\n",
    "# the training model is not stateful and trains on 4 second sequences\n",
    "# the predcition model is stateful and the internal state will persist between predictions\n",
    "def createModel(for_training):\n",
    "    if for_training:\n",
    "        layer_input = Input(shape = (seq_len, num_features))\n",
    "        is_stateful = False\n",
    "    else:\n",
    "        layer_input = Input(batch_shape = (1, 1, num_features))\n",
    "        is_stateful = True\n",
    "        \n",
    "    '''layer_hid1 = LSTM(400, stateful=is_stateful, return_sequences=True)(layer_input)\n",
    "    dropout = Dropout(0.2)(layer_hid1)\n",
    "    layer_hid2 = LSTM(400, stateful=is_stateful, return_sequences=True)(dropout)\n",
    "    dropout2 = Dropout(0.2)(layer_hid2)\n",
    "    layer_hid3 = Dense(100)(dropout2)\n",
    "    layer_hid3 = LeakyReLU(alpha=0.05)(layer_hid3)\n",
    "    dropout3 = Dropout(0.2)(layer_hid3)'''\n",
    "    \n",
    "    layer_hid1 = LSTM(600, stateful=is_stateful, return_sequences=True)(layer_input)\n",
    "    dropout = Dropout(0.2)(layer_hid1)\n",
    "    layer_hid2 = LSTM(500, stateful=is_stateful, return_sequences=True)(dropout)\n",
    "    dropout2 = Dropout(0.2)(layer_hid2)\n",
    "    layer_hid3 = Dense(200)(dropout2)\n",
    "    layer_hid3 = LeakyReLU(alpha=0.05)(layer_hid3)\n",
    "    dropout3 = Dropout(0.2)(layer_hid3)\n",
    "    \n",
    "    # button outputs are probabilistic, goal angles are regressional\n",
    "    layer_out1 = Dense(output_size_y1, activation = 'sigmoid', name='layer_out1')(dropout3)\n",
    "    layer_out2 = Dense(output_size_y2, activation = 'linear', name='layer_out2')(dropout3)\n",
    "\n",
    "    model = Model(inputs=layer_input, outputs=[layer_out1, layer_out2])\n",
    "\n",
    "    if for_training:\n",
    "        model.compile(\n",
    "            loss={'layer_out1' : 'binary_crossentropy', 'layer_out2' : 'mean_squared_error'}, \n",
    "            loss_weights = {'layer_out1' : 8, 'layer_out2' : 0.5}, # 8, 0.5\n",
    "            optimizer='adam', \n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "training_model = createModel(True)\n",
    "\n",
    "if not new_model:\n",
    "    training_model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint_path = \"checkpoint_1\\\\cp.ckpt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Train</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 103228 samples\n",
      "Epoch 1/500\n",
      "103168/103228 [============================>.] - ETA: 0s - loss: 4.2703 - layer_out1_loss: 0.0764 - layer_out2_loss: 7.3176 - layer_out1_accuracy: 0.9699 - layer_out2_accuracy: 0.9734\n",
      "Epoch 00001: saving model to checkpoint_1\\cp.ckpt\n",
      "103228/103228 [==============================] - 119s 1ms/sample - loss: 4.2694 - layer_out1_loss: 0.0764 - layer_out2_loss: 7.3141 - layer_out1_accuracy: 0.9699 - layer_out2_accuracy: 0.9734\n",
      "Epoch 2/500\n",
      "103168/103228 [============================>.] - ETA: 0s - loss: 2.4056 - layer_out1_loss: 0.0454 - layer_out2_loss: 4.0847 - layer_out1_accuracy: 0.9823 - layer_out2_accuracy: 0.9802\n",
      "Epoch 00002: saving model to checkpoint_1\\cp.ckpt\n",
      "103228/103228 [==============================] - 113s 1ms/sample - loss: 2.4055 - layer_out1_loss: 0.0454 - layer_out2_loss: 4.0845 - layer_out1_accuracy: 0.9823 - layer_out2_accuracy: 0.9802\n",
      "Epoch 3/500\n",
      "103168/103228 [============================>.] - ETA: 0s - loss: 2.2452 - layer_out1_loss: 0.0375 - layer_out2_loss: 3.8912 - layer_out1_accuracy: 0.9857 - layer_out2_accuracy: 0.9808\n",
      "Epoch 00003: saving model to checkpoint_1\\cp.ckpt\n",
      "103228/103228 [==============================] - 114s 1ms/sample - loss: 2.2453 - layer_out1_loss: 0.0375 - layer_out2_loss: 3.8914 - layer_out1_accuracy: 0.9857 - layer_out2_accuracy: 0.9808\n",
      "Epoch 4/500\n",
      "103168/103228 [============================>.] - ETA: 0s - loss: 2.0992 - layer_out1_loss: 0.0327 - layer_out2_loss: 3.6752 - layer_out1_accuracy: 0.9876 - layer_out2_accuracy: 0.9816\n",
      "Epoch 00004: saving model to checkpoint_1\\cp.ckpt\n",
      "103228/103228 [==============================] - 112s 1ms/sample - loss: 2.0992 - layer_out1_loss: 0.0327 - layer_out2_loss: 3.6753 - layer_out1_accuracy: 0.9876 - layer_out2_accuracy: 0.9816\n",
      "Epoch 5/500\n",
      "103168/103228 [============================>.] - ETA: 0s - loss: 2.0581 - layer_out1_loss: 0.0308 - layer_out2_loss: 3.6228 - layer_out1_accuracy: 0.9883 - layer_out2_accuracy: 0.9818\n",
      "Epoch 00005: saving model to checkpoint_1\\cp.ckpt\n",
      "103228/103228 [==============================] - 115s 1ms/sample - loss: 2.0579 - layer_out1_loss: 0.0308 - layer_out2_loss: 3.6223 - layer_out1_accuracy: 0.9883 - layer_out2_accuracy: 0.9818\n",
      "Epoch 6/500\n",
      "103168/103228 [============================>.] - ETA: 0s - loss: 1.9694 - layer_out1_loss: 0.0286 - layer_out2_loss: 3.4811 - layer_out1_accuracy: 0.9892 - layer_out2_accuracy: 0.9823\n",
      "Epoch 00006: saving model to checkpoint_1\\cp.ckpt\n",
      "103228/103228 [==============================] - 110s 1ms/sample - loss: 1.9694 - layer_out1_loss: 0.0286 - layer_out2_loss: 3.4810 - layer_out1_accuracy: 0.9892 - layer_out2_accuracy: 0.9823\n",
      "Epoch 7/500\n",
      "103168/103228 [============================>.] - ETA: 0s - loss: 1.9241 - layer_out1_loss: 0.0267 - layer_out2_loss: 3.4202 - layer_out1_accuracy: 0.9899 - layer_out2_accuracy: 0.9826\n",
      "Epoch 00007: saving model to checkpoint_1\\cp.ckpt\n",
      "103228/103228 [==============================] - 114s 1ms/sample - loss: 1.9240 - layer_out1_loss: 0.0267 - layer_out2_loss: 3.4199 - layer_out1_accuracy: 0.9899 - layer_out2_accuracy: 0.9826\n",
      "Epoch 8/500\n",
      "103168/103228 [============================>.] - ETA: 0s - loss: 1.8350 - layer_out1_loss: 0.0251 - layer_out2_loss: 3.2689 - layer_out1_accuracy: 0.9905 - layer_out2_accuracy: 0.9831\n",
      "Epoch 00008: saving model to checkpoint_1\\cp.ckpt\n",
      "103228/103228 [==============================] - 114s 1ms/sample - loss: 1.8350 - layer_out1_loss: 0.0251 - layer_out2_loss: 3.2688 - layer_out1_accuracy: 0.9905 - layer_out2_accuracy: 0.9831\n",
      "Epoch 9/500\n",
      "103168/103228 [============================>.] - ETA: 0s - loss: 1.8047 - layer_out1_loss: 0.0242 - layer_out2_loss: 3.2228 - layer_out1_accuracy: 0.9909 - layer_out2_accuracy: 0.9832\n",
      "Epoch 00009: saving model to checkpoint_1\\cp.ckpt\n",
      "103228/103228 [==============================] - 109s 1ms/sample - loss: 1.8047 - layer_out1_loss: 0.0242 - layer_out2_loss: 3.2227 - layer_out1_accuracy: 0.9909 - layer_out2_accuracy: 0.9832\n",
      "Epoch 10/500\n",
      "103168/103228 [============================>.] - ETA: 0s - loss: 1.7899 - layer_out1_loss: 0.0235 - layer_out2_loss: 3.2038 - layer_out1_accuracy: 0.9912 - layer_out2_accuracy: 0.9833\n",
      "Epoch 00010: saving model to checkpoint_1\\cp.ckpt\n",
      "103228/103228 [==============================] - 112s 1ms/sample - loss: 1.7898 - layer_out1_loss: 0.0235 - layer_out2_loss: 3.2036 - layer_out1_accuracy: 0.9912 - layer_out2_accuracy: 0.9833\n",
      "Epoch 11/500\n",
      "103168/103228 [============================>.] - ETA: 0s - loss: 1.8987 - layer_out1_loss: 0.0250 - layer_out2_loss: 3.3972 - layer_out1_accuracy: 0.9906 - layer_out2_accuracy: 0.9827\n",
      "Epoch 00011: saving model to checkpoint_1\\cp.ckpt\n",
      "103228/103228 [==============================] - 109s 1ms/sample - loss: 1.8986 - layer_out1_loss: 0.0250 - layer_out2_loss: 3.3967 - layer_out1_accuracy: 0.9906 - layer_out2_accuracy: 0.9827\n",
      "Epoch 12/500\n",
      "103168/103228 [============================>.] - ETA: 0s - loss: 1.8042 - layer_out1_loss: 0.0231 - layer_out2_loss: 3.2392 - layer_out1_accuracy: 0.9913 - layer_out2_accuracy: 0.9832\n",
      "Epoch 00012: saving model to checkpoint_1\\cp.ckpt\n",
      "103228/103228 [==============================] - 117s 1ms/sample - loss: 1.8041 - layer_out1_loss: 0.0231 - layer_out2_loss: 3.2389 - layer_out1_accuracy: 0.9913 - layer_out2_accuracy: 0.9832\n",
      "Epoch 13/500\n",
      "103168/103228 [============================>.] - ETA: 0s - loss: 1.7251 - layer_out1_loss: 0.0218 - layer_out2_loss: 3.1014 - layer_out1_accuracy: 0.9918 - layer_out2_accuracy: 0.9836\n",
      "Epoch 00013: saving model to checkpoint_1\\cp.ckpt\n",
      "103228/103228 [==============================] - 109s 1ms/sample - loss: 1.7250 - layer_out1_loss: 0.0218 - layer_out2_loss: 3.1014 - layer_out1_accuracy: 0.9918 - layer_out2_accuracy: 0.9836\n",
      "Epoch 14/500\n",
      "103168/103228 [============================>.] - ETA: 0s - loss: 1.6725 - layer_out1_loss: 0.0207 - layer_out2_loss: 3.0136 - layer_out1_accuracy: 0.9922 - layer_out2_accuracy: 0.9839\n",
      "Epoch 00014: saving model to checkpoint_1\\cp.ckpt\n",
      "103228/103228 [==============================] - 112s 1ms/sample - loss: 1.6724 - layer_out1_loss: 0.0207 - layer_out2_loss: 3.0135 - layer_out1_accuracy: 0.9922 - layer_out2_accuracy: 0.9839\n",
      "Epoch 15/500\n",
      "103168/103228 [============================>.] - ETA: 0s - loss: 1.7120 - layer_out1_loss: 0.0210 - layer_out2_loss: 3.0888 - layer_out1_accuracy: 0.9922 - layer_out2_accuracy: 0.9836\n",
      "Epoch 00015: saving model to checkpoint_1\\cp.ckpt\n",
      "103228/103228 [==============================] - 115s 1ms/sample - loss: 1.7120 - layer_out1_loss: 0.0210 - layer_out2_loss: 3.0887 - layer_out1_accuracy: 0.9922 - layer_out2_accuracy: 0.9836\n",
      "Epoch 16/500\n",
      "103168/103228 [============================>.] - ETA: 0s - loss: 1.6515 - layer_out1_loss: 0.0199 - layer_out2_loss: 2.9851 - layer_out1_accuracy: 0.9926 - layer_out2_accuracy: 0.9840\n",
      "Epoch 00016: saving model to checkpoint_1\\cp.ckpt\n",
      "103228/103228 [==============================] - 112s 1ms/sample - loss: 1.6514 - layer_out1_loss: 0.0199 - layer_out2_loss: 2.9849 - layer_out1_accuracy: 0.9926 - layer_out2_accuracy: 0.9840\n",
      "Epoch 17/500\n",
      "  2432/103228 [..............................] - ETA: 1:47 - loss: 1.6278 - layer_out1_loss: 0.0194 - layer_out2_loss: 2.9451 - layer_out1_accuracy: 0.9927 - layer_out2_accuracy: 0.9834\n",
      "Epoch 00017: saving model to checkpoint_1\\cp.ckpt\n",
      "  2432/103228 [..............................] - ETA: 1:52 - loss: 1.6278 - layer_out1_loss: 0.0194 - layer_out2_loss: 2.9451 - layer_out1_accuracy: 0.9927 - layer_out2_accuracy: 0.9834"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-54aa8daca09b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m history = training_model.fit(x_train, {'layer_out1' : y1_train, 'layer_out2' : y2_train},\n\u001b[0;32m      7\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                     callbacks=[cp_callback])\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\mine\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mine\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mine\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mine\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mine\\lib\\site-packages\\tensorflow_core\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mine\\lib\\site-packages\\tensorflow_core\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mine\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36m_non_none_constant_value\u001b[1;34m(v)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_non_none_constant_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m   \u001b[0mconstant_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mine\\lib\\site-packages\\tensorflow_core\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36mconstant_value\u001b[1;34m(tensor, partial)\u001b[0m\n\u001b[0;32m    820\u001b[0m   \"\"\"\n\u001b[0;32m    821\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mine\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    940\u001b[0m     \"\"\"\n\u001b[0;32m    941\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mine\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    906\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 908\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    909\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "history = training_model.fit(x_train, {'layer_out1' : y1_train, 'layer_out2' : y2_train},\n",
    "                    epochs=500, batch_size = 128, shuffle=True,\n",
    "                    callbacks=[cp_callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create and save stateful prediction model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(1, 1, 79)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (1, 1, 600)          1632000     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (1, 1, 600)          0           lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   (1, 1, 500)          2202000     dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (1, 1, 500)          0           lstm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (1, 1, 200)          100200      dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (1, 1, 200)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (1, 1, 200)          0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_out1 (Dense)              (1, 1, 21)           4221        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_out2 (Dense)              (1, 1, 2)            402         dropout_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,938,823\n",
      "Trainable params: 3,938,823\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "prediction_model = createModel(False)\n",
    "prediction_model.load_weights(checkpoint_path)\n",
    "prediction_model.save('mordhai.h5', include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mine",
   "language": "python",
   "name": "mine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
