{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Imports</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob, os\n",
    "import random\n",
    "import sklearn\n",
    "import tensorflow as tf  \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, LSTM, LeakyReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Config Tensorflow to use GPU</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce RTX 2080, pci bus id: 0000:08:00.0, compute capability: 7.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = tf.compat.v1.ConfigProto()  \n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU  \n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)  \n",
    "                                    # (nothing gets printed in Jupyter, only if you run it standalone)\n",
    "sess = tf.compat.v1.Session(config=config)  \n",
    "tf.compat.v1.keras.backend.set_session(sess)  # set this TensorFlow session as the default session for Keras  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load raw data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "\n",
    "for file in glob.glob(\"C:\\\\Users\\\\Jordan\\\\Desktop\\\\data\\\\*.txt\"):\n",
    "    data_file = open(file)\n",
    "    lines = lines + data_file.readlines()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Prepare training data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63902, 200, 36)\n",
      "(63902, 200, 16)\n",
      "(63902, 200, 2)\n"
     ]
    }
   ],
   "source": [
    "# each sample consists of 3 lines,\n",
    "# Input state, output controls, output angle\n",
    "num_samples = len(lines) // 3\n",
    "seq_len = 200 # length of sequences to train on\n",
    "\n",
    "# has one input and two outputs, one for probabilistic output and other for regression\n",
    "data_x = []\n",
    "data_y1 = []\n",
    "data_y2 = []\n",
    "\n",
    "# format data into input list and output lists\n",
    "for i in range (0, num_samples * 3):\n",
    "    if i % 3 == 0:\n",
    "        data_x.append(np.fromstring(lines[i], dtype='float', sep=' '))\n",
    "        data_y1.append(np.fromstring(lines[i + 1], dtype='float', sep=' '))\n",
    "        data_y2.append(np.fromstring(lines[i + 2], dtype='float', sep=' '))\n",
    "\n",
    "# format data for training\n",
    "# has shape of (num sequences, seq length, number of features)\n",
    "x_train = []\n",
    "y1_train = []\n",
    "y2_train = []\n",
    "\n",
    "# create many sequences from a sliding window of 4 second sequences\n",
    "i = 0\n",
    "while i < num_samples - seq_len:\n",
    "    seq_x = []\n",
    "    seq_y1 = []\n",
    "    seq_y2 = []\n",
    "    \n",
    "    for j in range (i, i + seq_len):\n",
    "        seq_x.append(data_x[j])\n",
    "        seq_y1.append(data_y1[j])\n",
    "        seq_y2.append(data_y2[j])\n",
    "        \n",
    "    x_train.append(seq_x)\n",
    "    y1_train.append(seq_y1)\n",
    "    y2_train.append(seq_y2)\n",
    "    \n",
    "    i += random.randint(1, 10)\n",
    "        \n",
    "x_train = np.array(x_train)\n",
    "y1_train = np.array(y1_train)\n",
    "y2_train = np.array(y2_train)\n",
    "\n",
    "num_features = x_train[0][0].size\n",
    "output_size_y1 = y1_train[0][0].size\n",
    "output_size_y2 = y2_train[0][0].size\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y1_train.shape)\n",
    "print(y2_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 200, 36)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 200, 400)     699200      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 200, 400)     0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 200, 400)     1281600     dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 200, 400)     0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 200, 100)     40100       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 200, 100)     0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 200, 100)     0           leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_out1 (Dense)              (None, 200, 16)      1616        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_out2 (Dense)              (None, 200, 2)       202         dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,022,718\n",
      "Trainable params: 2,022,718\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = False\n",
    "checkpoint_path = \"training_5\\\\cp.ckpt\"\n",
    "\n",
    "# creates the neural network\n",
    "# the training model is not stateful and trains on 4 second sequences\n",
    "# the predcition model is stateful and the internal state will persist between predictions\n",
    "def createModel(for_training):\n",
    "    if for_training:\n",
    "        layer_input = Input(shape = (seq_len, num_features))\n",
    "        is_stateful = False\n",
    "    else:\n",
    "        layer_input = Input(batch_shape = (1, 1, num_features))\n",
    "        is_stateful = True\n",
    "    \n",
    "    layer_hid1 = LSTM(400, stateful=is_stateful, return_sequences=True)(layer_input)\n",
    "    dropout = Dropout(0.2)(layer_hid1)\n",
    "    layer_hid2 = LSTM(400, stateful=is_stateful, return_sequences=True)(dropout)\n",
    "    dropout2 = Dropout(0.2)(layer_hid2)\n",
    "    layer_hid3 = Dense(100)(dropout2)\n",
    "    layer_hid3 = LeakyReLU(alpha=0.05)(layer_hid3)\n",
    "    dropout3 = Dropout(0.2)(layer_hid3)\n",
    "    \n",
    "    # button outputs are probabilistic, goal angles are regressional\n",
    "    layer_out1 = Dense(output_size_y1, activation = 'sigmoid', name='layer_out1')(dropout3)\n",
    "    layer_out2 = Dense(output_size_y2, activation = 'linear', name='layer_out2')(dropout3)\n",
    "\n",
    "    model = Model(inputs=layer_input, outputs=[layer_out1, layer_out2])\n",
    "\n",
    "    if for_training:\n",
    "        model.compile(\n",
    "            loss={'layer_out1' : 'binary_crossentropy', 'layer_out2' : 'mean_squared_error'}, \n",
    "            loss_weights = {'layer_out1' : 8, 'layer_out2' : 0.5}, # 8, 0.5\n",
    "            optimizer='adam', \n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "training_model = createModel(True)\n",
    "\n",
    "if not new_model:\n",
    "    training_model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Train</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 63902 samples\n",
      "Epoch 1/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 48.1469 - layer_out1_loss: 0.2083 - layer_out2_loss: 92.9615 - layer_out1_accuracy: 0.9063 - layer_out2_accuracy: 0.9026\n",
      "Epoch 00001: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 40s 620us/sample - loss: 48.0750 - layer_out1_loss: 0.2082 - layer_out2_loss: 92.7299 - layer_out1_accuracy: 0.9063 - layer_out2_accuracy: 0.9027\n",
      "Epoch 2/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 16.0254 - layer_out1_loss: 0.1863 - layer_out2_loss: 29.0695 - layer_out1_accuracy: 0.9176 - layer_out2_accuracy: 0.9387\n",
      "Epoch 00002: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 40s 621us/sample - loss: 16.0226 - layer_out1_loss: 0.1863 - layer_out2_loss: 29.0605 - layer_out1_accuracy: 0.9176 - layer_out2_accuracy: 0.9387\n",
      "Epoch 3/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 12.8021 - layer_out1_loss: 0.1766 - layer_out2_loss: 22.7779 - layer_out1_accuracy: 0.9224 - layer_out2_accuracy: 0.9456\n",
      "Epoch 00003: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 39s 616us/sample - loss: 12.7988 - layer_out1_loss: 0.1766 - layer_out2_loss: 22.7676 - layer_out1_accuracy: 0.9224 - layer_out2_accuracy: 0.9456\n",
      "Epoch 4/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 11.2015 - layer_out1_loss: 0.1688 - layer_out2_loss: 19.7024 - layer_out1_accuracy: 0.9264 - layer_out2_accuracy: 0.9491\n",
      "Epoch 00004: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 40s 619us/sample - loss: 11.1975 - layer_out1_loss: 0.1688 - layer_out2_loss: 19.6898 - layer_out1_accuracy: 0.9264 - layer_out2_accuracy: 0.9491\n",
      "Epoch 5/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 10.0825 - layer_out1_loss: 0.1612 - layer_out2_loss: 17.5859 - layer_out1_accuracy: 0.9303 - layer_out2_accuracy: 0.9519\n",
      "Epoch 00005: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 39s 614us/sample - loss: 10.0808 - layer_out1_loss: 0.1612 - layer_out2_loss: 17.5807 - layer_out1_accuracy: 0.9303 - layer_out2_accuracy: 0.9519\n",
      "Epoch 6/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 9.2107 - layer_out1_loss: 0.1539 - layer_out2_loss: 15.9582 - layer_out1_accuracy: 0.9340 - layer_out2_accuracy: 0.9537\n",
      "Epoch 00006: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 40s 623us/sample - loss: 9.2113 - layer_out1_loss: 0.1540 - layer_out2_loss: 15.9601 - layer_out1_accuracy: 0.9340 - layer_out2_accuracy: 0.9537\n",
      "Epoch 7/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 8.6277 - layer_out1_loss: 0.1470 - layer_out2_loss: 14.9029 - layer_out1_accuracy: 0.9374 - layer_out2_accuracy: 0.9550\n",
      "Epoch 00007: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 40s 622us/sample - loss: 8.6267 - layer_out1_loss: 0.1470 - layer_out2_loss: 14.8996 - layer_out1_accuracy: 0.9374 - layer_out2_accuracy: 0.9550\n",
      "Epoch 8/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 8.0849 - layer_out1_loss: 0.1403 - layer_out2_loss: 13.9255 - layer_out1_accuracy: 0.9408 - layer_out2_accuracy: 0.9564\n",
      "Epoch 00008: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 40s 633us/sample - loss: 8.0846 - layer_out1_loss: 0.1403 - layer_out2_loss: 13.9248 - layer_out1_accuracy: 0.9408 - layer_out2_accuracy: 0.9563\n",
      "Epoch 9/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 7.7266 - layer_out1_loss: 0.1340 - layer_out2_loss: 13.3100 - layer_out1_accuracy: 0.9440 - layer_out2_accuracy: 0.9572\n",
      "Epoch 00009: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 41s 636us/sample - loss: 7.7262 - layer_out1_loss: 0.1339 - layer_out2_loss: 13.3091 - layer_out1_accuracy: 0.9441 - layer_out2_accuracy: 0.9572\n",
      "Epoch 10/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 7.3681 - layer_out1_loss: 0.1275 - layer_out2_loss: 12.6961 - layer_out1_accuracy: 0.9473 - layer_out2_accuracy: 0.9583\n",
      "Epoch 00010: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 41s 635us/sample - loss: 7.3682 - layer_out1_loss: 0.1275 - layer_out2_loss: 12.6966 - layer_out1_accuracy: 0.9473 - layer_out2_accuracy: 0.9583\n",
      "Epoch 11/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 7.0336 - layer_out1_loss: 0.1211 - layer_out2_loss: 12.1291 - layer_out1_accuracy: 0.9505 - layer_out2_accuracy: 0.9590\n",
      "Epoch 00011: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 42s 660us/sample - loss: 7.0328 - layer_out1_loss: 0.1211 - layer_out2_loss: 12.1270 - layer_out1_accuracy: 0.9505 - layer_out2_accuracy: 0.9590\n",
      "Epoch 12/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 6.7232 - layer_out1_loss: 0.1149 - layer_out2_loss: 11.6079 - layer_out1_accuracy: 0.9536 - layer_out2_accuracy: 0.9598\n",
      "Epoch 00012: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 40s 628us/sample - loss: 6.7227 - layer_out1_loss: 0.1149 - layer_out2_loss: 11.6067 - layer_out1_accuracy: 0.9536 - layer_out2_accuracy: 0.9598\n",
      "Epoch 13/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 6.4913 - layer_out1_loss: 0.1095 - layer_out2_loss: 11.2301 - layer_out1_accuracy: 0.9563 - layer_out2_accuracy: 0.9604\n",
      "Epoch 00013: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 40s 621us/sample - loss: 6.4904 - layer_out1_loss: 0.1095 - layer_out2_loss: 11.2273 - layer_out1_accuracy: 0.9563 - layer_out2_accuracy: 0.9604\n",
      "Epoch 14/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 6.3080 - layer_out1_loss: 0.1051 - layer_out2_loss: 10.9347 - layer_out1_accuracy: 0.9584 - layer_out2_accuracy: 0.9607\n",
      "Epoch 00014: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 41s 640us/sample - loss: 6.3092 - layer_out1_loss: 0.1051 - layer_out2_loss: 10.9390 - layer_out1_accuracy: 0.9584 - layer_out2_accuracy: 0.9607\n",
      "Epoch 15/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 6.0709 - layer_out1_loss: 0.1008 - layer_out2_loss: 10.5283 - layer_out1_accuracy: 0.9604 - layer_out2_accuracy: 0.9614\n",
      "Epoch 00015: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 42s 657us/sample - loss: 6.0705 - layer_out1_loss: 0.1008 - layer_out2_loss: 10.5271 - layer_out1_accuracy: 0.9604 - layer_out2_accuracy: 0.9614\n",
      "Epoch 16/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 5.8946 - layer_out1_loss: 0.0971 - layer_out2_loss: 10.2359 - layer_out1_accuracy: 0.9621 - layer_out2_accuracy: 0.9619\n",
      "Epoch 00016: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 42s 660us/sample - loss: 5.8939 - layer_out1_loss: 0.0971 - layer_out2_loss: 10.2337 - layer_out1_accuracy: 0.9621 - layer_out2_accuracy: 0.9619\n",
      "Epoch 17/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 5.7190 - layer_out1_loss: 0.0937 - layer_out2_loss: 9.9383 - layer_out1_accuracy: 0.9636 - layer_out2_accuracy: 0.9624\n",
      "Epoch 00017: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 42s 651us/sample - loss: 5.7195 - layer_out1_loss: 0.0937 - layer_out2_loss: 9.9395 - layer_out1_accuracy: 0.9636 - layer_out2_accuracy: 0.9624\n",
      "Epoch 18/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 5.5976 - layer_out1_loss: 0.0909 - layer_out2_loss: 9.7413 - layer_out1_accuracy: 0.9649 - layer_out2_accuracy: 0.9629\n",
      "Epoch 00018: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 41s 648us/sample - loss: 5.6009 - layer_out1_loss: 0.0909 - layer_out2_loss: 9.7520 - layer_out1_accuracy: 0.9649 - layer_out2_accuracy: 0.9629\n",
      "Epoch 19/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 5.5476 - layer_out1_loss: 0.0889 - layer_out2_loss: 9.6731 - layer_out1_accuracy: 0.9658 - layer_out2_accuracy: 0.9629\n",
      "Epoch 00019: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 39s 613us/sample - loss: 5.5470 - layer_out1_loss: 0.0889 - layer_out2_loss: 9.6712 - layer_out1_accuracy: 0.9658 - layer_out2_accuracy: 0.9629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 5.3033 - layer_out1_loss: 0.0857 - layer_out2_loss: 9.2357 - layer_out1_accuracy: 0.9672 - layer_out2_accuracy: 0.9635\n",
      "Epoch 00020: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 40s 621us/sample - loss: 5.3044 - layer_out1_loss: 0.0857 - layer_out2_loss: 9.2394 - layer_out1_accuracy: 0.9672 - layer_out2_accuracy: 0.9635\n",
      "Epoch 21/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 5.2338 - layer_out1_loss: 0.0836 - layer_out2_loss: 9.1294 - layer_out1_accuracy: 0.9681 - layer_out2_accuracy: 0.9640\n",
      "Epoch 00021: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 40s 631us/sample - loss: 5.2335 - layer_out1_loss: 0.0836 - layer_out2_loss: 9.1284 - layer_out1_accuracy: 0.9681 - layer_out2_accuracy: 0.9640\n",
      "Epoch 22/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 5.1178 - layer_out1_loss: 0.0816 - layer_out2_loss: 8.9300 - layer_out1_accuracy: 0.9689 - layer_out2_accuracy: 0.9642\n",
      "Epoch 00022: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 42s 657us/sample - loss: 5.1178 - layer_out1_loss: 0.0816 - layer_out2_loss: 8.9300 - layer_out1_accuracy: 0.9689 - layer_out2_accuracy: 0.9642\n",
      "Epoch 23/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 5.0558 - layer_out1_loss: 0.0801 - layer_out2_loss: 8.8298 - layer_out1_accuracy: 0.9695 - layer_out2_accuracy: 0.9644\n",
      "Epoch 00023: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 43s 673us/sample - loss: 5.0564 - layer_out1_loss: 0.0801 - layer_out2_loss: 8.8316 - layer_out1_accuracy: 0.9695 - layer_out2_accuracy: 0.9644\n",
      "Epoch 24/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 5.0174 - layer_out1_loss: 0.0787 - layer_out2_loss: 8.7761 - layer_out1_accuracy: 0.9702 - layer_out2_accuracy: 0.9644\n",
      "Epoch 00024: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 42s 652us/sample - loss: 5.0167 - layer_out1_loss: 0.0787 - layer_out2_loss: 8.7742 - layer_out1_accuracy: 0.9702 - layer_out2_accuracy: 0.9644\n",
      "Epoch 25/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 4.8777 - layer_out1_loss: 0.0768 - layer_out2_loss: 8.5259 - layer_out1_accuracy: 0.9709 - layer_out2_accuracy: 0.9649\n",
      "Epoch 00025: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 42s 662us/sample - loss: 4.8768 - layer_out1_loss: 0.0768 - layer_out2_loss: 8.5229 - layer_out1_accuracy: 0.9709 - layer_out2_accuracy: 0.9649\n",
      "Epoch 26/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 4.7474 - layer_out1_loss: 0.0751 - layer_out2_loss: 8.2939 - layer_out1_accuracy: 0.9716 - layer_out2_accuracy: 0.9652\n",
      "Epoch 00026: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 40s 631us/sample - loss: 4.7474 - layer_out1_loss: 0.0751 - layer_out2_loss: 8.2938 - layer_out1_accuracy: 0.9716 - layer_out2_accuracy: 0.9652\n",
      "Epoch 27/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 4.8307 - layer_out1_loss: 0.0752 - layer_out2_loss: 8.4581 - layer_out1_accuracy: 0.9716 - layer_out2_accuracy: 0.9648\n",
      "Epoch 00027: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 41s 647us/sample - loss: 4.8302 - layer_out1_loss: 0.0752 - layer_out2_loss: 8.4566 - layer_out1_accuracy: 0.9716 - layer_out2_accuracy: 0.9648\n",
      "Epoch 28/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 4.6206 - layer_out1_loss: 0.0726 - layer_out2_loss: 8.0801 - layer_out1_accuracy: 0.9726 - layer_out2_accuracy: 0.9656\n",
      "Epoch 00028: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 41s 647us/sample - loss: 4.6207 - layer_out1_loss: 0.0726 - layer_out2_loss: 8.0806 - layer_out1_accuracy: 0.9726 - layer_out2_accuracy: 0.9656\n",
      "Epoch 29/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 5.0197 - layer_out1_loss: 0.0767 - layer_out2_loss: 8.8123 - layer_out1_accuracy: 0.9710 - layer_out2_accuracy: 0.9641\n",
      "Epoch 00029: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 41s 643us/sample - loss: 5.0183 - layer_out1_loss: 0.0767 - layer_out2_loss: 8.8080 - layer_out1_accuracy: 0.9710 - layer_out2_accuracy: 0.9641\n",
      "Epoch 30/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 4.7350 - layer_out1_loss: 0.0730 - layer_out2_loss: 8.3013 - layer_out1_accuracy: 0.9724 - layer_out2_accuracy: 0.9650\n",
      "Epoch 00030: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 41s 647us/sample - loss: 4.7352 - layer_out1_loss: 0.0730 - layer_out2_loss: 8.3020 - layer_out1_accuracy: 0.9724 - layer_out2_accuracy: 0.9650\n",
      "Epoch 31/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 4.5170 - layer_out1_loss: 0.0704 - layer_out2_loss: 7.9076 - layer_out1_accuracy: 0.9734 - layer_out2_accuracy: 0.9659\n",
      "Epoch 00031: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 42s 653us/sample - loss: 4.5163 - layer_out1_loss: 0.0704 - layer_out2_loss: 7.9053 - layer_out1_accuracy: 0.9734 - layer_out2_accuracy: 0.9659\n",
      "Epoch 32/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 4.4192 - layer_out1_loss: 0.0689 - layer_out2_loss: 7.7355 - layer_out1_accuracy: 0.9740 - layer_out2_accuracy: 0.9663\n",
      "Epoch 00032: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 42s 663us/sample - loss: 4.4191 - layer_out1_loss: 0.0689 - layer_out2_loss: 7.7354 - layer_out1_accuracy: 0.9740 - layer_out2_accuracy: 0.9663\n",
      "Epoch 33/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 4.3424 - layer_out1_loss: 0.0678 - layer_out2_loss: 7.6004 - layer_out1_accuracy: 0.9745 - layer_out2_accuracy: 0.9665\n",
      "Epoch 00033: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 42s 661us/sample - loss: 4.3422 - layer_out1_loss: 0.0678 - layer_out2_loss: 7.5999 - layer_out1_accuracy: 0.9745 - layer_out2_accuracy: 0.9665\n",
      "Epoch 34/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 4.2800 - layer_out1_loss: 0.0668 - layer_out2_loss: 7.4906 - layer_out1_accuracy: 0.9748 - layer_out2_accuracy: 0.9667\n",
      "Epoch 00034: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 42s 660us/sample - loss: 4.2804 - layer_out1_loss: 0.0668 - layer_out2_loss: 7.4919 - layer_out1_accuracy: 0.9748 - layer_out2_accuracy: 0.9667\n",
      "Epoch 35/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 4.2373 - layer_out1_loss: 0.0659 - layer_out2_loss: 7.4195 - layer_out1_accuracy: 0.9752 - layer_out2_accuracy: 0.9670\n",
      "Epoch 00035: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 45s 704us/sample - loss: 4.2369 - layer_out1_loss: 0.0659 - layer_out2_loss: 7.4185 - layer_out1_accuracy: 0.9752 - layer_out2_accuracy: 0.9670\n",
      "Epoch 36/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 4.2077 - layer_out1_loss: 0.0651 - layer_out2_loss: 7.3737 - layer_out1_accuracy: 0.9755 - layer_out2_accuracy: 0.9669\n",
      "Epoch 00036: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 42s 653us/sample - loss: 4.2070 - layer_out1_loss: 0.0651 - layer_out2_loss: 7.3718 - layer_out1_accuracy: 0.9755 - layer_out2_accuracy: 0.9669\n",
      "Epoch 37/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 4.2195 - layer_out1_loss: 0.0646 - layer_out2_loss: 7.4052 - layer_out1_accuracy: 0.9757 - layer_out2_accuracy: 0.9670\n",
      "Epoch 00037: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 40s 628us/sample - loss: 4.2192 - layer_out1_loss: 0.0646 - layer_out2_loss: 7.4044 - layer_out1_accuracy: 0.9757 - layer_out2_accuracy: 0.9670\n",
      "Epoch 38/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 4.1313 - layer_out1_loss: 0.0635 - layer_out2_loss: 7.2467 - layer_out1_accuracy: 0.9761 - layer_out2_accuracy: 0.9672\n",
      "Epoch 00038: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 40s 624us/sample - loss: 4.1313 - layer_out1_loss: 0.0635 - layer_out2_loss: 7.2466 - layer_out1_accuracy: 0.9761 - layer_out2_accuracy: 0.9672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 4.1039 - layer_out1_loss: 0.0627 - layer_out2_loss: 7.2044 - layer_out1_accuracy: 0.9764 - layer_out2_accuracy: 0.9674\n",
      "Epoch 00039: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 40s 630us/sample - loss: 4.1052 - layer_out1_loss: 0.0627 - layer_out2_loss: 7.2084 - layer_out1_accuracy: 0.9764 - layer_out2_accuracy: 0.9674\n",
      "Epoch 40/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 4.1043 - layer_out1_loss: 0.0623 - layer_out2_loss: 7.2120 - layer_out1_accuracy: 0.9766 - layer_out2_accuracy: 0.9672\n",
      "Epoch 00040: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 40s 631us/sample - loss: 4.1042 - layer_out1_loss: 0.0623 - layer_out2_loss: 7.2116 - layer_out1_accuracy: 0.9766 - layer_out2_accuracy: 0.9672\n",
      "Epoch 41/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 4.0262 - layer_out1_loss: 0.0612 - layer_out2_loss: 7.0731 - layer_out1_accuracy: 0.9770 - layer_out2_accuracy: 0.9675\n",
      "Epoch 00041: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 41s 636us/sample - loss: 4.0261 - layer_out1_loss: 0.0612 - layer_out2_loss: 7.0727 - layer_out1_accuracy: 0.9770 - layer_out2_accuracy: 0.9675\n",
      "Epoch 42/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 3.9764 - layer_out1_loss: 0.0603 - layer_out2_loss: 6.9883 - layer_out1_accuracy: 0.9773 - layer_out2_accuracy: 0.9678\n",
      "Epoch 00042: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 41s 639us/sample - loss: 3.9766 - layer_out1_loss: 0.0603 - layer_out2_loss: 6.9887 - layer_out1_accuracy: 0.9773 - layer_out2_accuracy: 0.9678\n",
      "Epoch 43/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 3.9627 - layer_out1_loss: 0.0597 - layer_out2_loss: 6.9697 - layer_out1_accuracy: 0.9776 - layer_out2_accuracy: 0.9677\n",
      "Epoch 00043: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 42s 659us/sample - loss: 3.9621 - layer_out1_loss: 0.0597 - layer_out2_loss: 6.9682 - layer_out1_accuracy: 0.9776 - layer_out2_accuracy: 0.9677\n",
      "Epoch 44/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 3.9552 - layer_out1_loss: 0.0592 - layer_out2_loss: 6.9638 - layer_out1_accuracy: 0.9778 - layer_out2_accuracy: 0.9676\n",
      "Epoch 00044: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 44s 688us/sample - loss: 3.9554 - layer_out1_loss: 0.0592 - layer_out2_loss: 6.9641 - layer_out1_accuracy: 0.9778 - layer_out2_accuracy: 0.9676\n",
      "Epoch 45/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 3.9814 - layer_out1_loss: 0.0591 - layer_out2_loss: 7.0177 - layer_out1_accuracy: 0.9778 - layer_out2_accuracy: 0.9675\n",
      "Epoch 00045: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 43s 666us/sample - loss: 3.9819 - layer_out1_loss: 0.0591 - layer_out2_loss: 7.0192 - layer_out1_accuracy: 0.9778 - layer_out2_accuracy: 0.9675\n",
      "Epoch 46/1000\n",
      "63744/63902 [============================>.] - ETA: 0s - loss: 4.1046 - layer_out1_loss: 0.0600 - layer_out2_loss: 7.2491 - layer_out1_accuracy: 0.9775 - layer_out2_accuracy: 0.9671\n",
      "Epoch 00046: saving model to training_5/cp.ckpt\n",
      "63902/63902 [==============================] - 44s 683us/sample - loss: 4.1055 - layer_out1_loss: 0.0600 - layer_out2_loss: 7.2517 - layer_out1_accuracy: 0.9775 - layer_out2_accuracy: 0.9671\n",
      "Epoch 47/1000\n",
      "60160/63902 [===========================>..] - ETA: 2s - loss: 4.0036 - layer_out1_loss: 0.0587 - layer_out2_loss: 7.0683 - layer_out1_accuracy: 0.9780 - layer_out2_accuracy: 0.9675"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "history = training_model.fit(x_train, {'layer_out1' : y1_train, 'layer_out2' : y2_train},\n",
    "                    epochs=1000, batch_size = 256, shuffle=True,\n",
    "                    callbacks=[cp_callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create and save stateful prediction model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(1, 1, 36)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_10 (LSTM)                  (1, 1, 400)          699200      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (1, 1, 400)          0           lstm_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_11 (LSTM)                  (1, 1, 400)          1281600     dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (1, 1, 400)          0           lstm_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (1, 1, 100)          40100       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (1, 1, 100)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (1, 1, 100)          0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_out1 (Dense)              (1, 1, 16)           1616        dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_out2 (Dense)              (1, 1, 2)            202         dropout_15[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 2,022,718\n",
      "Trainable params: 2,022,718\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "prediction_model = createModel(False)\n",
    "prediction_model.load_weights(checkpoint_path)\n",
    "prediction_model.save('mordhai.h5', include_optimizer=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mine",
   "language": "python",
   "name": "mine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
